{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ],
      "metadata": {
        "id": "y43FBcORrJqE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job=input(\"Enter the job to be searched:\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTt9TFFQzv59",
        "outputId": "7c68b4d5-a352-41e7-af29-8daec679aa0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the job to be searched:data-analytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract(page):\n",
        "  headers={'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'}\n",
        "  url=f'https://internshala.com/jobs/{job}-jobs/page-{page}/'\n",
        "  r=requests.get(url,headers)\n",
        "  soup=BeautifulSoup(r.content,'html.parser')\n",
        "  return soup\n",
        "soup=extract(1)"
      ],
      "metadata": {
        "id": "e31G0NR92r9_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages=soup.find('span',id='total_pages').text"
      ],
      "metadata": {
        "id": "8hmzWdCv2Uvc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform(soup):\n",
        "  divs = soup.find_all('div', class_='company')\n",
        "  Ttitle = []\n",
        "  Ccompany = []\n",
        "\n",
        "  for item in divs:\n",
        "    anchors = item.find_all('a')\n",
        "    if len(anchors) >= 2:\n",
        "      title = anchors[0].text.strip()\n",
        "      company = anchors[1].text.strip()\n",
        "      Ttitle.append(title)\n",
        "      Ccompany.append(company)\n",
        "  return Ttitle, Ccompany\n",
        "\n",
        "def transformm(soup):\n",
        "    divs = soup.find_all('div', class_='other_detail_item_row')\n",
        "    salaries = []  # Declare the list to store salaries\n",
        "    for div in divs:\n",
        "        salary = div.find('div', class_='item_body salary').text.strip()\n",
        "        salaries.append(salary)\n",
        "    return salaries"
      ],
      "metadata": {
        "id": "FwYUReB2rWGn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ttitle = []\n",
        "Ccompany = []\n",
        "salaries = []\n",
        "\n",
        "for i in range(1, int(pages) + 1):\n",
        "    soup = extract(i)\n",
        "    Ttitle_current, Ccompany_current = transform(soup)\n",
        "    salaries_current = transformm(soup)\n",
        "\n",
        "    Ttitle += Ttitle_current\n",
        "    Ccompany += Ccompany_current\n",
        "    salaries += salaries_current"
      ],
      "metadata": {
        "id": "ZkwM9Ury4mwH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_csv(title, company, salary, filename):\n",
        "    data = zip(title, company, salary)\n",
        "    with open(filename, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Title', 'Company', 'Salary'])\n",
        "        writer.writerows(data)\n",
        "create_csv(Ttitle, Ccompany, salaries, 'output.csv')"
      ],
      "metadata": {
        "id": "5vuT10byetOv"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}